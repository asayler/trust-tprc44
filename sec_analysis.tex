\section{Analysis of Services}
\label{sec:analysis}

The trust model proposed in \S~\ref{sec:model} is primarily useful for
what it can tell us about the nature of user trust and the modern
computing landscape. As such, I apply the model to analyze the
capabilities granted to a number of popular third party computing
services.

\subsection{Third Party Capabilities}
\label{sec:analysis:capabilites}

Third party based ``cloud'' computing services have become extremely
popular over the previous 10 years.  The question of how
\textit{trustworthy} these services are is addressed later in
~\S~\ref{sec:analysis:violations}. In this section, I explore how
\textit{trusted} such service are. That is, how much trust must users
place in such services? The capability axis of my proposed model is
useful to quantify this trust.

\subsubsection{File Storage}

Cloud file storage is a popular third party use case. Services such as
Dropbox~\cite{dropbox}, Google Drive~\cite{google-drive}, and
Microsoft OneDrive~\cite{microsoft-onedrive} all provide users with
mechanisms for storing their files in the cloud, often for the purpose
of keeping files synced across multiple devices or to provide the
ability to share files or collaboratively edit them with other
users. Traditional cloud storage services such as Dropbox, Drive, and
OneDrive are similar enough in their operation that I will use Dropbox
as a stand in for the analysis of all three.

What capabilities is a normal Dropbox user entrusting to Dropbox?
Clearly, users must trust Dropbox to faithfully store their data since
that is Dropbox's core purpose. Users therefore grant Dropbox the
\emph{S} capability. Furthermore, users must also grant Dropbox the
ability to read and access their data (i.e. the \emph{R} capability)
in order to support Dropbox's sharing and syncing features. While
Dropbox doesn't generally utilize it, users are also effectively
granting Dropbox the manipulation (\emph{W} capability) as well since
the user has no mechanisms for ensuring that Dropbox can't manipulate
their data. Finally, Dropbox has full access to user metadata related
to their usage of the service, granting them the \emph{M}
capability. Therefore, Dropbox users must trust Dropbox with all
possible capabilities. Traditional cloud storage services such as
Dropbox, Drive, and OneDrive are thus classified as ``fully trusted''
services: service that require the highest possible level of user
trust. Such services, are thus also in a position to do the greatest
degree of damage to user privacy should a users trust in them as
faithful stewards of private data turn out to be misplaced.

The level of trust requested by tradition cloud storage servers
rightfully makes some user nervous or unwilling to use such
services. In response to such aversion, a number of systems have been
developed with the aim of overcoming third party trust challenges in
the storage space. These systems include ``end-to-end'' encrypted file
storage services such as Tresorit~\cite{tresorit}, or
SpiderOak~\cite{spideroak}. These systems aim to place limits on a
third party's ability to leverage the access (\emph{R}) capability
through the use of client-side encryption. Likewise, they aim to limit
third party access to the manipulation (\emph{W}) capability through
the use of client-side cryptographic
authentication.\footnote{E.g. asymmetric cryptographic signatures such
  as those provided by GnuPG~\cite{gnupg} or symmetric cryptographic
  message authentication codes (MACs) available via a variety of
  algorithms~\cite{dworkin2005, dworkin2007, dworkin2008}.}  In the
base case where a user merely wishes to store data on a single device
and not share it with others, these systems are fairly successful in
achieving their desired trust mitigations. In order to sync data
across multiple devices using such systems, a user must manually
provide some secret (e.g. a password, etc) on each device to secure
its operation. While potentially burdensome and inconvenient, this
practice is in line with these services trusted capabilities
mitigation since it does not require any additional third party trust.

The place where these systems falter at mitigating third party trust
is via their support for multi-user sharing and collaboration. Such
services tend to accomplish multi-user sharing by acting as a trusted
certificate authority (CA) in charge of issuing user
certificates.\footnote{A certificate is a combination of a user's
  public key and certain metadata signed by a trusted issuer. See for
  more information.}These certificates are then used with various
asymmetric cryptographic primitives) to exchange the necessary secrets
for bootstrapping sharing between users. Unfortunately, as a trusted
CA, these services are capable of issuing fraudulent user certificates
to themselves or other parties. This allows them to mount
man-in-the-middle (MitM) attacks on any user trying to share data by
impersonating the recipient of the shared data. This deficiency is
discussed in depth at~\cite{wilson2014}, and leads to a breakdown of
such services' claim that their users need not trust them, at least
when employing multi-user sharing. By mounting a MitM attack on a user
trying to share data with another user, such service providers can
regain the \emph{R} and \emph{W} capabilities they claim not to
have. Furthermore, these services do little to mitigate their access
to metadata (\emph{M} capability). Nor do they provide ways for users
to avoid data loss in the event that one of the services goes offline
or shuts down (\emph{S} capability).

``Secure'' cloud file storage service such as Tresorit do more to
minimize the required degree of third party trust then traditional
services such as Dropbox. In single-user scenarios, such services
succeed at reducing the degree of user trust from full (all four
capabilities) to partial (only requiring the \emph{S} and \emph{M}
capabilities). Yet, when implementing multi-user use cases, such
services fall back to requiring a more-or-less full degree of trust,
leaving much to be desired.

\subsubsection{Social Media}

Social media sites such as Facebook, Google Plus, etc have become
popular since the early 2000s. Such sites maintain a ``social-graph''
of connections between users, and facilitate communication and sharing
of pictures, events, and other data between users. Such sites are
generally ``free'' to users -- monetizing user data and interactions
for the purpose of selling targeted advertising. Given their ubiquity
in the modern Internet landscape, as well as their position as
ad-supported services, it is useful to evaluate the trust profile of
modern social media sites. Facebook is the largest social media site
today, serving over 1.5 billion users as of 2015~\cite{foster2014}. As
such, Facebook serves as an example of the variety of social media
sites available today.

In terms of capabilities, Facebook, like Dropbox and other traditional
cloud services, must be trusted with a full range of capabilities.
Facebook is responsible for faithfully storing user data such as
photos, videos, and messages. Facebook can access and read all data it
stores, and indeed relies on the ability to read such data as the
basis of their advertising-based business model. Facebook can
manipulate the data it stores, and routinely does so for the purpose
of curating user ``news feeds'' or even integrating user pictures into
targets ads~\cite{mashable-socialads}. Finally, Facebook is capable of
applying a range of meta-analytic techniques to acquire additional
data about users for the purpose of targeting both ads as well as
content from other users.

Other social media sites such as Google+~\cite{google-plus}
require similar levels of trust. And since all mainstream social media
services operate on add-supported business models, there are
business-related barriers to reducing this level of trust where doing
so would also reduce the level of access to user data. Thus, unlike in
the storage space, there are not really any options for ``secure''
social media platforms that specifically aim to minimize third party
trust.

\subsubsection{Communications}

Communication systems ranging from email and chat to voice and video
calling are another popular set of third party services. The privacy
and security of these systems are a matter of great public concern,
and indeed many of the current privacy and security related legal
battles revolve around the ability to communicates in a private and
secure manner (e.g.~\cite{apple-fbiletter, greenwald-prism,
  levsion-lavabit}). Communication systems range from traditional
communications services such as Gmail~\cite{google-gmail} to recent
privacy-enhancing services such as
TextSecure~\cite{otr-advanced-ratchet}.

Email services such as Gmail~\cite{google-gmail} or chat services such
as Hangouts~\cite{google-hangouts} represent a fairly traditional
approach to third party communication services. As was the case with
Dropbox and Facebook, users of such services must rely on the third
party service provider (in this case, Google) to properly store
(\emph{S} capability) their messages while the design of these systems
do nothing to prevent the service provider from accessing (\emph{R}
capability) or manipulating (\emph{W} capability) user
messages.\footnote{Similar to Facebook, many communication services
  are ad-based, and thus the service provider often relies on their
  ability to access user data as the basis of their business
  models.}Furthermore, since all communication flows through the
service provider's servers, these providers have access to a range of
potentially reveling meta-data about their users (\emph{M}
capability).

The need to place a high degree of trust in various third parties in
order to leverage digital communication services has long been a
concern. Indeed many early privacy-enhancing software projects,
including the venerable PGP~\cite{zimmermann-pgp10,
  zimmermann-pgpsource}, were created in response to the lack of
privacy inherent in most digital communication systems. Modern
implementation of such systems, such as those conforming to the
OpenPGP protocol~\cite{callas2007}, aim to reduce the amount users
must trust third party communication providers by adding end-to-end
encryption and cryptographic authentication support to traditional
digital communication mediums. The OpenPGP protocol can be applied
atop mail traversing traditional email systems such as Gmail, as well
as to messages traversing chat applications such as Hangouts. When
used with such services, OpenPGP provides a level of trust mitigation
above and beyond what is possible to achieve via the native services
themselves. In terms of trusted capabilities, a user employing PGP
atop a traditional third party cloud service such as Gmail minimizes
both the third party's access (via encryption) and manipulation (via
authentication) capabilities. In such a scenario, only the end users
involved in a given communication, and not any third party through
which that communication might pass, have access to the necessary
cryptographic keys required to read or alter the message. The third
party, however, can still capture metadata (\emph{M} capability) about
the communication since such metadata is outside of the scope of the
message content that PGP is capable of securing. The third party is
also still capable of dropping or deleting the communication all
together, and thus still possesses the \emph{S} capability.

Due to the numerous challenges and deficiencies associated with using
OpenPGP-based systems~\cite{green-pgp, borisov2004, whitten1999},
developers have created a number of alternate secure communication
protocols. These protocols aim to provide forward-secrecy, metadata
privacy, deniability, contact authentication, and message encryption
and authentication for (primarily) real-time communication such as
instant messaging and chat systems. Examples of such protocol include
OTR~\cite{otr-v3} and OTR-derived protocols like
TextSecure~\cite{otr-advanced-ratchet}. The TextSecure protocol is
used by several apps such Open Whisper System's
Signal~\cite{openwhisper} and WhatsApp~\cite{whatsapp}. TextSecure
uses various forms of asymmetric cryptography to provide users with
end-to-end encrypted and authenticated individual and group messaging
capabilities. Use of TextSecure denies any third party through which
TextSecure messages might pass (including the TextSecure server
itself) the access or manipulation capabilities. Furthermore,
TextSecure makes efforts to secure metadata from third party actors,
including the TextSecure server provider itself. These efforts curtail
a third party's ability to analyze message metadata. It is still
possible for a network-level adversary or the TextSecure server
provider to discover the raw network (e.g. IP) endpoints involved in a
TextSecure exchange, but higher level details are not
available.\footnote{It is possible to couple TextSecure with existing
  network anonymity systems such as Tor~\cite{dingledine2004} to
  mitigate such network-level
  meta-analysis~\cite{intercept-chatting}.}TextSecure users are still
dependent on a third party to operate a TextSecure server in order to
communicate in the first place (e.g. it is not a distributed
protocol), but beyond this ``storage''-like capability, TextSecure
grants no other capabilities to any third party.

Following the trend set by traditional cloud services such as Dropbox
and Facebook, traditional communication systems such as Gmail (and
email in general) or Hangouts (and related chat systems) require user
to place a high degree of trust in the corresponding third party
service providers. Overlay privacy-enhancing systems such as those
implementation the OpenPGP protocol allow users to reduce this level
of trust by leveraging client-side cryptography to prevent third
parties from levering the access (\emph{R}) or manipulation (\emph{W})
capabilities. Modern full-stack privacy-focused communication
protocols such as those implementing flavors of the OTR protocol take
these privacy-preserving cryptography techniques a step further by
providing primitives for limiting third party metadata access in
addition to protecting user data from third party access or
manipulation.

\subsubsection{Password Managers}

Password management programs are commonly used by end users wishing to
both manage and increase the security of the credentials they use to
access web-based resources. Such programs are useful for helping end
users remember passwords, and by extension, for encouraging users to
use stronger (i.e. longer and/or more random)
passwords~\cite{brodkin-passman, krebs-passwords,
  schneier-passwords}. Since Password managers potentially have access
to user credentials -- access to which would allow an adversary to
access a range of user data, including many of the cloud services
previously discussed, it is worth evaluating the trust user much place
in such services.

LastPass~\cite{lastpass} is one of the most popular cloud-based
password managers. LastPass operates by storing encrypted user
passwords on a LastPass-controlled server. Passwords are encrypted on
the client and only encrypted passwords are sent to LastPass. Each
password is encrypted using a key derived from a user-supplied
``master'' password. LastPass never stores this master password
directly, making it difficult for them to derive the key necessary to
decrypt the encrypted data they store. Thus, LastPass intentionally
limits its ``access'' (\emph{R} capability) to user
passwords. LastPass does not, however, appear to perform any kind of
cryptographic authentication on the data it stores, meaning it still
has full capabilities over the ``manipulation'' (\emph{W})
capability.\footnote{Such a lack of client-side cryptographic
  protections against modification leaves the door open to a range of
  potential attacks on LastPass's client side encryption as per the
  ``cryptographic doom'' principle~\cite{marlinspike-doom}.}Similarly,
LastPass is fully responsible for faithfully storing user data and has
full access to all user metadata associated with any stored
password. Thus LastPass, requires users to trust it with three of the
possible four capabilities -- less trust than cloud services such as
Facebook or Dropbox, but more than is strictly necessary to perform
its password storage duties.

Other open-source password managers such as KeePass~\cite{keepass},
Password Safe~\cite{passwordsafe}, or Pass~\cite{pass} exist with the
aim toward reducing the need to trust one or more third parties. Such
systems accomplish this by either requiring no third party support at
all (e.g. a purely local password manager)\footnote{Such purely
  client-side solutions limit third party trust, but do so at the
  expense of usability -- e.g. such solutions rarely provide users
  with the ability to access their passwords from multiple devices or
  to share passwords with colleagues.}or by allowing the user to
decouple encryption and authentication operation from optional third
party backend data storage and sync providers such as Dropbox. In
addition to liming third party access capability via encryption, such
services often aim to limit both manipulation and metadata
capabilities via the use of client-side cryptography.

\subsection{Violation Examples}
\label{sec:analysis:violations}

%% But how likely is it that Dropbox might misuse any of these
%% capabilities, thus violating the user's trust? In terms of implicit
%% violations (\emph{I}), Dropbox charges users for storage, and thus
%% shouldn't generally rely on reading or sharing user data for
%% advertising purposes. Furthermore, such a business model relies on
%% Dropbox remaining in its paying users' good graces, disincentivizing
%% potentially questionable behavior. Nonetheless, the user has no way to
%% prevent an \emph{I} violation when using Dropbox, so users can do no
%% more than give Dropbox the benefit of the doubt in this area.

%% In terms of compelled (\emph{C}) violations, Dropbox is a U.S.-based
%% company, and is thus susceptible to a variety of government-sponsored
%% data requests, from subpoenas issued under the Third Party
%% Doctrine~\cite{thompson-thirdparty}, to probable cause search
%% warrants~\cite{us-constitution-amend4}, to National Security
%% Letters~\cite{fbi-nsl}, to Foreign Intelligence Surveillance Court
%% (FISC)~\cite{fisc} orders. Dropbox publishes a transparency
%% report~\cite{dropbox-transparency} indicating how frequently they are
%% compelled to violate user privacy. Recent versions of this report
%% indicate that Dropbox receives a few hundred requests for various user
%% data every six months.

%% Unintentional (\emph{U}), Insider (\emph{I}), or Outsider (\emph{O})
%% violations are all possibilities when using Dropbox. On the \emph{U}
%% front, Dropbox had an incident in 2011 that allowed anyone to log into
%% the service using any password for a five hour
%% period~\cite{dropbox-authbug}. So far, Dropbox appears to have
%% avoided any \emph{I}-type violations, but it has been the target of
%% various \emph{O}-type attempted violations, primarily built around
%% advisories who obtain common user
%% passwords~\cite{dropbox-passwords}. Needless to say, while Dropbox
%% works to avoid these kinds of violations, they are certainly still
%% possible, have occurred in the past, and may well occur in the future.


%% In terms of trust violations, such ``secure'' cloud storage services
%% are being paid to store user data, disincentivizing implicit
%% violations. Compelled violations are possible, although as services
%% that market themselves as ``privacy'' products, compelled violations
%% (assuming they are public) are also disincentivized. Due to the CA
%% trust requirements that exists in such services' sharing
%% implementations, however, it is possible that such a service could be
%% compelled to mount a MitM attack on one of their users in order to
%% provide such data to the compelling party (similar to government
%% efforts to compel Apple to create a flawed version of iOS that would
%% be vulnerable to brute force attacks~\cite{ars-cookvfbi}). Similarly,
%% such a service could be compelled to surrender their CA private key,
%% allowing the compelling party to take over the trusted CA role and
%% mount such a MitM attack themselves (similar to the how Lavabit was
%% compelled to turn over their private TLS keys to facilitate government
%% access to the data they controlled~\cite{levsion-lavabit}). The fact
%% that such capabilities have been exploited for the purpose of
%% committing compelled violations in the past raises the likelihood of
%% such violations when using services such as Tresorit in the
%% future. Unintentional, Insider, and Outsider violations are all
%% similar to the traditional use case: such violations are technically
%% possible, but the third party has a vested interest in avoiding such
%% violations for reputation-related reasons. Collusion violations aren't
%% really applicable since Tresorit is a single-party actor.

%% Furthermore, since services such as Tresorit are not open source or
%% widely audited by independent parties, the user must trust that the
%% code they are running to access these services is faithfully
%% implementing the security guarantees the services claim to
%% support. It is possible that such a service could ship a flawed
%% version of their code due to a wide range of trust violations
%% (e.g. they could be compelled to ship such code, or it could be an
%% honest unintentional mistake).

%% In terms of likelihood of trust violations, Facebook differs a bit
%% from cloud-based system like Dropbox in that it is an ad-supported
%% system. This increases the likelihood of implicit trust failures due
%% to Facebook's business model being based around the sale of user
%% data. Indeed, and as mentioned in Chapter~\ref{chap:challenges},
%% Facebook has a record of implicit trust violations ranging from the
%% Emotional Contagion Study~\cite{goel2014} to its use of users' photos
%% in the ads it serves~\cite{mashable-socialads}. Beyond implicit trust
%% violations, Facebook's trust violation profile is again similar to
%% other traditional cloud services such as Dropbox. Like
%% Dropbox~\cite{dropbox-transparency}, compelled violations are known to
%% occur~\cite{facebook-transparency}. Unintentional, insider, and
%% outsider violations are all possible, but Facebook has an active
%% interest in avoiding them. Collusion violations aren't really
%% applicable since Facebook is a single-party actor.


%% Like Facebook, both services are ad-supported, increasing the
%% likelihood of implicit trust violations (although unlike Facebook,
%% Google seems to have a better track record of not committing such
%% violations). Similarly, both services are known to be subject to
%% compelled violations~\cite{google-transparency},\footnote{It is
%%   possible such cloud communication services are actually at an
%%   increased risk of compelled violations relative to other cloud
%%   services due to the existence of laws such as the Communications
%%   Assistance for Law Enforcement Act (CALEA)~\cite{calea-usc,
%%     calea-fcc} specifically designed to aid the government in
%%   obtaining a user's communications.}and are disincentivized, although
%% by no means immune, from committing unintentional, insider, and
%% outsider violations.\footnote{Google has taken steps to ensure
%%   communication between all of its data centers and between mail
%%   servers are encrypted in transit, helping to minimize outsider
%%   violations~\cite{gmail-blog-encryption}. Similarly, it has recently
%%   started providing end users with information as to whether or not
%%   encrypted email transmission was possible and whether or not an
%%   email's sender has been authenticated~\cite{gmail-blog-indicators}.
%%   In both cases however, third parties, not end users, remain in full
%%   control of all the necessary cryptographic keys, limiting this
%%   protection to the mitigation of outsider violations, and doing
%%   little to mitigate Implicit, Compelled, Unintentional, or Insider
%%   violations.}Thus, Google is able to analyze, alter, and expose any
%% data that travels across its network using either service -- either of
%% its own volition or due to a compelled order or unauthorized data
%% breach.


%% Since the OpenPGP protocol and associated implementations are not
%% controlled by any single third party, there is no straightforward
%% analysis of its likelihood of PGP-related trust violations. In
%% general, however, PGP implementations are controlled by parties with a
%% vested interest in maintaining user security and privacy. Such parties
%% are strongly disincentivized from committing implicit or compelled
%% violations. Most OpenPGP implementations are also open source. This
%% helps to mitigate\footnote{Although it does not necessarily prevent
%%   such violations, e.g. as in Heartbleed~\cite{heartbleed} or a Ken
%%   Thompson style attack~\cite{thompson1984}.}unintentional, insider,
%% and outsider violations by maximizing the number of eyes on the code
%% and reducing the likelihood of mistakes or intentionally coded
%% vulnerabilities and back doors.


%% Like OpenPGP, TextSecure is a protocol implemented by several
%% different apps. Such application providers (e.g. Open Whisper Systems)
%% specifically market their products as being a secure alternative to
%% more traditional chat systems, and are thus strongly dissuaded from
%% committing any kind of implicit or compelled trust
%% violation. Furthermore, most TextSecure implementations are open
%% source, which mitigates the likelihood of
%% unintentional,\footnote{Researchers have discovered bugs in
%%   TextSecure, but these bugs were quickly
%%   patched~\cite{frosch2014}.}insider, or outsider
%% violations. TextSecure has also undergone external audits and reviews,
%% further decreasing the likelihood of an unintentional or insider
%% violation~\cite{frosch2014}. As in OpenPGP, even if a violation
%% occurred, the capability restrictions discussed above severely limit
%% what data the violation would expose. Therefore, TextSecure represents
%% a successful effort to reduce third party trust exposure and secure
%% user communications.



%% In terms of likelihood of trust violations, LastPass has a very
%% similar profile to a service like Tresorit. LastPass is a ``freemium''
%% service that generates its income off its ability to faithfully store
%% and protect user passwords, encouraging users to pay for higher level
%% service tiers. This disincentivizes implicit trust
%% violations. LastPass also has a strong incentive to minimize (at least
%% public) compelled violations, although it is still subject to such
%% violations. Unintentional, insider, and outsider violations are
%% similarly disincentivized, although they have occurred
%% before~\cite{lastpass-blog-breach}.

%% Like Tresorit, LastPass is neither open source\footnote{Although parts
%%   of LastPass are build using JavaScript, which by its very nature
%%   exposes the source code to users. Nonetheless, such code can be
%%   obfuscated to make it difficult to read, and users lack most of the
%%   ``Free Software'' rights~\cite{fsf-freedoms} traditionally
%%   associated with ``open source'' code.}nor subject to public code
%% audits. As such, the user is required to trust that LastPass has
%% faithfully coded its software not to expose additional capabilities
%% via hidden back doors. It is possible that LastPass could be compelled
%% to modify the LastPass client program to do something like send copies
%% of a user's master password back to LastPass where it could be used to
%% decrypt all of the user's data. It is also possible that the lack of
%% cryptographic authentication on user data would allow LastPass to
%% mount a range of attacks on a user - potentially revealing one or more
%% of the passwords they store with LastPass in the process.


\subsubsection{Implicit Violations}

%% \begin{packed_desc}
%% \item[Facebook Emotional Contagion Study:] In 2014, it came to light
%%   that Facebook had engaged in research that involved manipulating
%%   what users saw in their newsfeeds in order to study the effects of
%%   one user's emotions on other users~\cite{goel2014}. The study was
%%   performed on $\approx700$ users without their knowledge or
%%   consent. Facebook misused the trust placed in it by its users by
%%   leveraging and manipulating their data in unforeseen ways.
%% \item[Uber User Travel History:] In 2014, ride-share app
%%   Uber~\cite{uber} made headlines when it used the travel history of a
%%   number of its more prominent users to display a live user-location
%%   map at a launch party~\cite{sims2014}. Similarly, the company also
%%   used stored user travel history to compose a blog post detailing its
%%   ability to detect a given user's proclivity for ``one night
%%   stands''~\cite{pagliery2014}. In both cases, Uber leveraged data it
%%   had about users in manners users did not approve of or intend.
%% \item[Target Pregnancy Prediction:] In 2012, it became public that
%%   Target had developed a statistical system for predicting if its
%%   shoppers were pregnant based on the kind of items they
%%   bought. Target would then leverage this data to send customers
%%   coupons optimized for pregnant individuals. In one case, this
%%   practice lead to the outing of a pregnant teenager to her previously
%%   unaware father~\cite{hill2012}. Clearly such outcomes are not within
%%   the realm of what most shoppers expect when purchasing items at
%%   Target.
%% \end{packed_desc}

\subsection{Compelled Violations}

%% \begin{packed_desc}
%% \item[PRISM and MUSCULAR:] The NSA PRISM program was/is a Foreign
%%   Intelligence Surveillance Court (FISC)~\cite{fisc} approved system
%%   for compelling service providers to provide user data to the
%%   government~\cite{greenwald-prism}. It is believed to be one of the
%%   largest programs used by the government to extract user data from
%%   various cloud-based services (e.g. Google, Yahoo, Microsoft,
%%   etc). Similarly, MUSCULAR was/is a joint NSA and U.K. Government
%%   Communication Headquarters (GCHQ) effort to intercept and monitor
%%   traffic traversing Google's and Yahoo's inter-datacenter
%%   networks~\cite{gellman-muscular}. Prior to MUSCULAR's disclosure,
%%   this intra-datacenter traffic was not generally encrypted, and thus
%%   was an ideal point for a third party (e.g. the government) to
%%   intercept and monitor user data. Both cases demonstrate a concerted
%%   government effort to access and monitor user data atop popular cloud
%%   services.
%% \item[Lavabit:] Lavabit was a private email service with 400,000 users
%%   premised on the idea that popular free email services such as Gmail
%%   lacked adequate security and privacy guarantees (in part due to the
%%   lesser legal protections such communications receive under the U.S.
%%   third party doctrine~\cite{thompson-thirdparty}). In August 2013
%%   Lavabit shuttered its service in response to a U.S. government
%%   subpoena requiring Lavabit to turn over all of its encrypted user
%%   traffic as well as the associated SSL encryption keys necessary to
%%   decrypt it~\cite{lavabit, levsion-lavabit}. After a legal fight,
%%   Lavabit founder Ladar Levison was forced to disclose the encryption
%%   keys protecting his service. The Lavabit example shows the
%%   government's willingness to compel service operators to aid in the
%%   monitoring and collection of user data.
%% \item[Apple v. FBI:] In response to the 2015 San Bernardino shootings,
%%   the FBI attempted to compel Apple to help it decrypt one of the
%%   shooters' iPhone~\cite{ars-cookvfbi}. The form of encryption Apple
%%   uses to protect the iPhone involves a hardware-linked encryption key
%%   that can not be easily extracted from the phone, limiting
%%   out-of-band cracking opportunities. Furthermore, this key can not be
%%   used on the phone without a user-provided passcode. By default,
%%   Apple limits the number of guesses a user may make at this passcode
%%   and throttles the speed at which a user may guess passcodes. The FBI
%%   wished to compel Apple to update the software on the iPhone so that
%%   they could try to guess an unlimited number of passcodes at a high
%%   rate of speed~\cite{eff-applecrypto}.\footnote{Due to Apple's use of
%%     signature-verified code, it is not possible for the FBI (or anyone
%%     else) to update the Apple's software themselves. Instead, Apple
%%     (or the holder of Apple's cryptographic code signing key)must
%%     approve and sign any updated code before the iPhone will run
%%     it.}Apple was disinclined to acquiesce to this
%%   request~\cite{apple-fbiletter}. The case wound up being dropped by
%%   the FBI after they were able to leverage an undisclosed security
%%   vulnerability to bypass Apple's passcode guessing limits
%%   directly~\cite{ars-fbi-greyhats, ars-fbi-breakthrough}. As in the
%%   Lavabit case, this case demonstrates the government's interest in
%%   compelling companies to assist them in accessing private user data,
%%   even going so far as to potentially require companies to avoid the
%%   use of certain forms of encryption or security-enhancing features
%%   that would make such assistance difficult or impossible to provide.
%% \end{packed_desc}

\subsubsection{Unintentional Violations}

%% \begin{packed_desc}
%% \item[Apple iCloud Celebrity Photo Leak:] In 2014, a number of
%%   celebrity users of Apple's iCloud data storage
%%   service~\cite{apple-icloud} were subject to a public release of
%%   personal photos they had stored with the service. This leak was the
%%   result of a targeted attack on the corresponding users' passwords
%%   and iCloud accounts~\cite{apple-icloudleak}. These attacks appear to
%%   have been propagated over several months prior to the public
%%   release. While this leak was not a result of an overt flaw in
%%   Apple's iCloud system, the weak default security requirements for
%%   iCloud accounts made it relatively simple for attackers to
%%   compromise such accounts and steal data.
%% \item[Office of Personnel Management Breach:] In 2015, the U.S. Office
%%   of Personnel Management (OPM) announced that their systems had been
%%   breached, exposing the personal data of essentially anyone who had
%%   held or currently holds a U.S. Government security
%%   clearance~\cite{ars-opmhack, opm-cybersecurityincidents}. This
%%   breach, in addition to having high strategic value to foreign
%%   attackers, reveled sensitive personnel data of a huge number of U.S.
%%   government employees and contractors. This leak was largely due to
%%   the use of old and outdated storage and security systems employed by
%%   the OPM.
%% \item[Anthem and Premera Blue Cross Breaches:] In early 2015 two major
%%   U.S. health insurance companies were subject to attacks that breached
%%   their user records, allowing the release of personal, financial, and
%%   medical information on millions of users~\cite{krebs-anthem,
%%     krebs-premera}. While the details of the breaches were not made
%%   public, such attacks demonstrate the risk of trusting a third party
%%   with the storage of large quantities of sensitive data.
%% \item[Heartbleed, Shellshock, etc:] In addition to targeted attacks,
%%   third parties are also susceptible to software flaws. Prominent
%%   examples of such flaws include Heartbleed~\cite{heartbleed}, a flaw
%%   in OpenSSL~\cite{openssl} that allowed attackers to steal private
%%   data from many secure servers, and
%%   Shellshock~\cite{symantec-shellshock}, a GNU bash~\cite{gnu-bash}
%%   flaw that allowed user to execute arbitrary code on many web
%%   servers. Both flaws were widespread and effected large swaths of
%%   web-connected sites and services, potentially exposing many users to
%%   attacks and data breaches.
%% \end{packed_desc}

\subsubsection{Collusion Violations}


\subsection{Risk Analysis}

%%  LocalWords:  OneDrive FISC Tresorit SpiderOak MACs MitM CALEA OTR
%%  LocalWords:  TextSecure WhatsApp LastPass LastPass's KeePass
