\section{Analysis of Services}
\label{sec:analysis}

The trust model proposed in \S~\ref{sec:model} is primarily useful for
what it can tell us about the nature of user trust and the modern
computing landscape. As such, I apply the model to analyze the
capabilities granted to a number of popular third party computing
services.

\subsection{Third Party Capabilities}
\label{sec:analysis:capabilites}

Third party based ``cloud'' computing services have become extremely
popular over the previous 10 years.  The question of how
\textit{trustworthy} these services are is addressed later in
~\S~\ref{sec:analysis:violations}. In this section, I explore how
\textit{trusted} such service are. That is, how much trust must users
place in such services? The capability axis of my proposed model is
useful to quantify this trust.

\subsubsection{File Storage}

Cloud file storage is a popular third party use case. Services such as
Dropbox~\cite{dropbox}, Google Drive~\cite{google-drive}, and
Microsoft OneDrive~\cite{microsoft-onedrive} all provide users with
mechanisms for storing their files in the cloud, often for the purpose
of keeping files synced across multiple devices or to provide the
ability to share files or collaboratively edit them with other
users. Traditional cloud storage services such as Dropbox, Drive, and
OneDrive are similar enough in their operation that I will use Dropbox
as a stand in for the analysis of all three.

What capabilities is a normal Dropbox user entrusting to Dropbox?
Clearly, users must trust Dropbox to faithfully store their data since
that is Dropbox's core purpose. Users therefore grant Dropbox the
\emph{S} capability. Furthermore, users must also grant Dropbox the
ability to read and access their data (i.e. the \emph{R} capability)
in order to support Dropbox's sharing and syncing features. While
Dropbox doesn't generally utilize it, users are also effectively
granting Dropbox the manipulation (\emph{W} capability) as well since
the user has no mechanisms for ensuring that Dropbox can't manipulate
their data. Finally, Dropbox has full access to user metadata related
to their usage of the service, granting them the \emph{M}
capability. Therefore, Dropbox users must trust Dropbox with all
possible capabilities. Traditional cloud storage services such as
Dropbox, Drive, and OneDrive are thus classified as ``fully trusted''
services: service that require the highest possible level of user
trust. Such services, are thus also in a position to do the greatest
degree of damage to user privacy should a users trust in them as
faithful stewards of private data turn out to be misplaced.

The level of trust requested by tradition cloud storage servers
rightfully makes some user nervous or unwilling to use such
services. In response to such aversion, a number of systems have been
developed with the aim of overcoming third party trust challenges in
the storage space. These systems include ``end-to-end'' encrypted file
storage services such as Tresorit~\cite{tresorit}, or
SpiderOak~\cite{spideroak}. These systems aim to place limits on a
third party's ability to leverage the access (\emph{R}) capability
through the use of client-side encryption. Likewise, they aim to limit
third party access to the manipulation (\emph{W}) capability through
the use of client-side cryptographic
authentication.\footnote{E.g. asymmetric cryptographic signatures such
  as those provided by GnuPG~\cite{gnupg} or symmetric cryptographic
  message authentication codes (MACs) available via a variety of
  algorithms~\cite{dworkin2005, dworkin2007, dworkin2008}.}  In the
base case where a user merely wishes to store data on a single device
and not share it with others, these systems are fairly successful in
achieving their desired trust mitigations. In order to sync data
across multiple devices using such systems, a user must manually
provide some secret (e.g. a password, etc) on each device to secure
its operation. While potentially burdensome and inconvenient, this
practice is in line with these services trusted capabilities
mitigation since it does not require any additional third party trust.

The place where these systems falter at mitigating third party trust
is via their support for multi-user sharing and collaboration. Such
services tend to accomplish multi-user sharing by acting as a trusted
certificate authority (CA) in charge of issuing user
certificates.\footnote{A certificate is a combination of a user's
  public key and certain metadata signed by a trusted issuer. See for
  more information.}These certificates are then used with various
asymmetric cryptographic primitives) to exchange the necessary secrets
for bootstrapping sharing between users. Unfortunately, as a trusted
CA, these services are capable of issuing fraudulent user certificates
to themselves or other parties. This allows them to mount
man-in-the-middle (MitM) attacks on any user trying to share data by
impersonating the recipient of the shared data. This deficiency is
discussed in depth at~\cite{wilson2014}, and leads to a breakdown of
such services' claim that their users need not trust them, at least
when employing multi-user sharing. By mounting a MitM attack on a user
trying to share data with another user, such service providers can
regain the \emph{R} and \emph{W} capabilities they claim not to
have. Furthermore, these services do little to mitigate their access
to metadata (\emph{M} capability). Nor do they provide ways for users
to avoid data loss in the event that one of the services goes offline
or shuts down (\emph{S} capability).

``Secure'' cloud file storage service such as Tresorit do more to
minimize the required degree of third party trust then traditional
services such as Dropbox. In single-user scenarios, such services
succeed at reducing the degree of user trust from full (all four
capabilities) to partial (only requiring the \emph{S} and \emph{M}
capabilities). Yet, when implementing multi-user use cases, such
services fall back to requiring a more-or-less full degree of trust,
leaving much to be desired.

\subsubsection{Social Media}

Social media sites such as Facebook, Google Plus, etc have become
popular since the early 2000s. Such sites maintain a ``social-graph''
of connections between users, and facilitate communication and sharing
of pictures, events, and other data between users. Such sites are
generally ``free'' to users -- monetizing user data and interactions
for the purpose of selling targeted advertising. Given their ubiquity
in the modern Internet landscape, as well as their position as
ad-supported services, it is useful to evaluate the trust profile of
modern social media sites. Facebook is the largest social media site
today, serving over 1.5 billion users as of 2015~\cite{foster2014}. As
such, Facebook serves as an example of the variety of social media
sites available today.

In terms of capabilities, Facebook, like Dropbox and other traditional
cloud services, must be trusted with a full range of capabilities.
Facebook is responsible for faithfully storing user data such as
photos, videos, and messages. Facebook can access and read all data it
stores, and indeed relies on the ability to read such data as the
basis of their advertising-based business model. Facebook can
manipulate the data it stores, and routinely does so for the purpose
of curating user ``news feeds'' or even integrating user pictures into
targets ads~\cite{mashable-socialads}. Finally, Facebook is capable of
applying a range of meta-analytic techniques to acquire additional
data about users for the purpose of targeting both ads as well as
content from other users.

Other social media sites such as Google+~\cite{google-plus}
require similar levels of trust. And since all mainstream social media
services operate on add-supported business models, there are
business-related barriers to reducing this level of trust where doing
so would also reduce the level of access to user data. Thus, unlike in
the storage space, there are not really any options for ``secure''
social media platforms that specifically aim to minimize third party
trust.

\subsubsection{Communications}

Communication systems ranging from email and chat to voice and video
calling are another popular set of third party services. The privacy
and security of these systems are a matter of great public concern,
and indeed many of the current privacy and security related legal
battles revolve around the ability to communicates in a private and
secure manner (e.g.~\cite{apple-fbiletter, greenwald-prism,
  levsion-lavabit}). Communication systems range from traditional
communications services such as Gmail~\cite{google-gmail} to recent
privacy-enhancing services such as
TextSecure~\cite{otr-advanced-ratchet}.

Email services such as Gmail~\cite{google-gmail} or chat services such
as Hangouts~\cite{google-hangouts} represent a fairly traditional
approach to third party communication services. As was the case with
Dropbox and Facebook, users of such services must rely on the third
party service provider (in this case, Google) to properly store
(\emph{S} capability) their messages while the design of these systems
do nothing to prevent the service provider from accessing (\emph{R}
capability) or manipulating (\emph{W} capability) user
messages.\footnote{Similar to Facebook, many communication services
  are ad-based, and thus the service provider often relies on their
  ability to access user data as the basis of their business
  models.}Furthermore, since all communication flows through the
service provider's servers, these providers have access to a range of
potentially reveling meta-data about their users (\emph{M}
capability).

The need to place a high degree of trust in various third parties in
order to leverage digital communication services has long been a
concern. Indeed many early privacy-enhancing software projects,
including the venerable PGP~\cite{zimmermann-pgp10,
  zimmermann-pgpsource}, were created in response to the lack of
privacy inherent in most digital communication systems. Modern
implementation of such systems, such as those conforming to the
OpenPGP protocol~\cite{callas2007}, aim to reduce the amount users
must trust third party communication providers by adding end-to-end
encryption and cryptographic authentication support to traditional
digital communication mediums. The OpenPGP protocol can be applied
atop mail traversing traditional email systems such as Gmail, as well
as to messages traversing chat applications such as Hangouts. When
used with such services, OpenPGP provides a level of trust mitigation
above and beyond what is possible to achieve via the native services
themselves. In terms of trusted capabilities, a user employing PGP
atop a traditional third party cloud service such as Gmail minimizes
both the third party's access (via encryption) and manipulation (via
authentication) capabilities. In such a scenario, only the end users
involved in a given communication, and not any third party through
which that communication might pass, have access to the necessary
cryptographic keys required to read or alter the message. The third
party, however, can still capture metadata (\emph{M} capability) about
the communication since such metadata is outside of the scope of the
message content that PGP is capable of securing. The third party is
also still capable of dropping or deleting the communication all
together, and thus still possesses the \emph{S} capability.

Due to the numerous challenges and deficiencies associated with using
OpenPGP-based systems~\cite{green-pgp, borisov2004, whitten1999},
developers have created a number of alternate secure communication
protocols. These protocols aim to provide forward-secrecy, metadata
privacy, deniability, contact authentication, and message encryption
and authentication for (primarily) real-time communication such as
instant messaging and chat systems. Examples of such protocol include
OTR~\cite{otr-v3} and OTR-derived protocols like
TextSecure~\cite{otr-advanced-ratchet}. The TextSecure protocol is
used by several apps such Open Whisper System's
Signal~\cite{openwhisper} and WhatsApp~\cite{whatsapp}. TextSecure
uses various forms of asymmetric cryptography to provide users with
end-to-end encrypted and authenticated individual and group messaging
capabilities. Use of TextSecure denies any third party through which
TextSecure messages might pass (including the TextSecure server
itself) the access or manipulation capabilities. Furthermore,
TextSecure makes efforts to secure metadata from third party actors,
including the TextSecure server provider itself. These efforts curtail
a third party's ability to analyze message metadata. It is still
possible for a network-level adversary or the TextSecure server
provider to discover the raw network (e.g. IP) endpoints involved in a
TextSecure exchange, but higher level details are not
available.\footnote{It is possible to couple TextSecure with existing
  network anonymity systems such as Tor~\cite{dingledine2004} to
  mitigate such network-level
  meta-analysis~\cite{intercept-chatting}.}TextSecure users are still
dependent on a third party to operate a TextSecure server in order to
communicate in the first place (e.g. it is not a distributed
protocol), but beyond this ``storage''-like capability, TextSecure
grants no other capabilities to any third party.

Following the trend set by traditional cloud services such as Dropbox
and Facebook, traditional communication systems such as Gmail (and
email in general) or Hangouts (and related chat systems) require user
to place a high degree of trust in the corresponding third party
service providers. Overlay privacy-enhancing systems such as those
implementation the OpenPGP protocol allow users to reduce this level
of trust by leveraging client-side cryptography to prevent third
parties from levering the access (\emph{R}) or manipulation (\emph{W})
capabilities. Modern full-stack privacy-focused communication
protocols such as those implementing flavors of the OTR protocol take
these privacy-preserving cryptography techniques a step further by
providing primitives for limiting third party metadata access in
addition to protecting user data from third party access or
manipulation.

\subsubsection{Password Managers}

Password management programs are commonly used by end users wishing to
both manage and increase the security of the credentials they use to
access web-based resources. Such programs are useful for helping end
users remember passwords, and by extension, for encouraging users to
use stronger (i.e. longer and/or more random)
passwords~\cite{brodkin-passman, krebs-passwords,
  schneier-passwords}. Since Password managers potentially have access
to user credentials -- access to which would allow an adversary to
access a range of user data, including many of the cloud services
previously discussed, it is worth evaluating the trust user much place
in such services.

LastPass~\cite{lastpass} is one of the most popular cloud-based
password managers. LastPass operates by storing encrypted user
passwords on a LastPass-controlled server. Passwords are encrypted on
the client and only encrypted passwords are sent to LastPass. Each
password is encrypted using a key derived from a user-supplied
``master'' password. LastPass never stores this master password
directly, making it difficult for them to derive the key necessary to
decrypt the encrypted data they store. Thus, LastPass intentionally
limits its ``access'' (\emph{R} capability) to user
passwords. LastPass does not, however, appear to perform any kind of
cryptographic authentication on the data it stores, meaning it still
has full capabilities over the ``manipulation'' (\emph{W})
capability.\footnote{Such a lack of client-side cryptographic
  protections against modification leaves the door open to a range of
  potential attacks on LastPass's client side encryption as per the
  ``cryptographic doom'' principle~\cite{marlinspike-doom}.}Similarly,
LastPass is fully responsible for faithfully storing user data and has
full access to all user metadata associated with any stored
password. Thus LastPass, requires users to trust it with three of the
possible four capabilities -- less trust than cloud services such as
Facebook or Dropbox, but more than is strictly necessary to perform
its password storage duties.

Other open-source password managers such as KeePass~\cite{keepass},
Password Safe~\cite{passwordsafe}, or Pass~\cite{pass} exist with the
aim toward reducing the need to trust one or more third parties. Such
systems accomplish this by either requiring no third party support at
all (e.g. a purely local password manager)\footnote{Such purely
  client-side solutions limit third party trust, but do so at the
  expense of usability -- e.g. such solutions rarely provide users
  with the ability to access their passwords from multiple devices or
  to share passwords with colleagues.}or by allowing the user to
decouple encryption and authentication operation from optional third
party backend data storage and sync providers such as Dropbox. In
addition to liming third party access capability via encryption, such
services often aim to limit both manipulation and metadata
capabilities via the use of client-side cryptography.

\subsection{Violation Examples}
\label{sec:analysis:violations}

Beyond the capabilities with with users must trust modern cloud
services lie the analysis of the likelihood that such trust will be
violated. In this section, I present an analysis of the factors and
incentivize and disincentive certain classes of trust violation (as
outlined in \S~\ref{sec:model}). I also provide examples of specific
trust violation events that have occurred over the previous ten years.

\subsubsection{Implicit Violations}

Implicit trust violations represent the most direct form of trust
violation. Implicit violation occur when a trust party intentionally
misuses a trusted capability in a eminent the user did not intend. As
the most direct for of violation, implicit violates are also present
the simplest analysis of incentives and disincentive regarding such
violations.

One of the clearest potential incentives for companies to commit
implicit trust violation comes via advertising-supported business
models employed by many cloud services. In these models, the user is
provided with access to a cloud service for ``free''. The service
provider monetizes their service either by selling advertising space
on the service directly or by collecting and selling user data to
third party advertising firms. In contrast to more traditional
mass-media based advertising schemes, cloud services are often
designed as platforms for highly targeted advertising. That is, cloud
services can leverage the vast amount of user data to which they have
access as a mechanism for building detailed dossiers on each user and
using these dossiers as the basis for serving personally tailored
adds. Advertisers are generally willing to pay higher prices for more
carefully tag red ads, incentivizing cloud providers to harvest user
data is pursuit of such targeting.

While such advertising practices do not inherently represents an
implicit trust violation, they do setup a series of perverse
incentives where companies can benefit by leveraging the access
(\emph{R}) capability to harvest user data. Most ad-support cloud
service require the user to agree to a terms of service that grants
the service provider the right to harvest user data for advertising
purposes. But it's well known that few, if any users, actually read
such terms, leading to situations where users are often surprised by
the way in which their data is used~\cite{hern2015}. Thus, while the
user may have technically ``agreed'' to certain advertising practices,
it is reasonable to still fault a service provider with having
committed an implicit trust violation in situations where their use of
user data deviations from that which the user would generally expect.

Target provides an example of an implicit trust violation triggered by
ad-motivated misuses of access to user data. In 2012, it became public
that Target had developed a statistical system for predicting if its
shoppers were pregnant based on the kind of items they bought. Target
would then leverage this data to send customers coupons optimized for
pregnant individuals. In one case, this practice lead to the outing of
a pregnant teenager to her previously unaware
father~\cite{hill2012}. Clearly such outcomes are not within the realm
of what most shoppers expect when purchasing items at Target. Facebook
committed a similar ad-motivated implicit trust violations when it
begin to incorporate user-provided images into the ads it served to
other users~\cite{mashable-socialads}. These actions caught many users
by sup rise as one does not normally expect their personal photos to
be re-purposed for the purpose of endorsing third party products.

Not all implicit violations are tied to the kinds of preference
incentives user-data driven advertising often elicits. Sometimes third
parties just make poor decisions about the manner in which to use the
capabilities a user has granted them. One of the more infamous
examples of such misuse comes from Facebook's ability to manipulate
(\emph{W} capability) user news feeds. In 2014, it came to light that
Facebook had engaged in research that involved manipulating what users
saw in their news feeds in order to study the effects of one user's
emotions on other users~\cite{goel2014}. The ``emotional contagion''
study was performed on $\approx700$ users without their knowledge or
consent. Facebook misused the trust placed in it by its users to
faithfully curates their news feeds to instead manipulate these feeds
in unforeseen and potentially behavior altering ways.

Some cloud coma pines rely on charging their users for access to a
given service, and are thus particular disincentivized from committing
implicit violations -- the revelations of which might harm their
business prospects. But such companies are not immune to committing
implicit violations. For example, in 2014, ride-share app
Uber~\cite{uber} made headlines when it used the travel history of a
number of its more prominent users to display a live user-location map
at a launch party~\cite{sims2014}. This map allowed party guests to
track these users in real time -- an outcome the average Uber user
certainly does not expect. Similarly, Uber also used stored user
travel history to compose a blog post detailing its ability to detect
a given user's proclivity for ``one night
stands''~\cite{pagliery2014}. In both cases, Uber committed implicit
trust violations by leveraging data it had about users in manners
users did not approve of or intend.

\subsection{Compelled Violations}

%% \begin{packed_desc}
%% \item[PRISM and MUSCULAR:] The NSA PRISM program was/is a Foreign
%%   Intelligence Surveillance Court (FISC)~\cite{fisc} approved system
%%   for compelling service providers to provide user data to the
%%   government~\cite{greenwald-prism}. It is believed to be one of the
%%   largest programs used by the government to extract user data from
%%   various cloud-based services (e.g. Google, Yahoo, Microsoft,
%%   etc). Similarly, MUSCULAR was/is a joint NSA and U.K. Government
%%   Communication Headquarters (GCHQ) effort to intercept and monitor
%%   traffic traversing Google's and Yahoo's inter-datacenter
%%   networks~\cite{gellman-muscular}. Prior to MUSCULAR's disclosure,
%%   this intra-datacenter traffic was not generally encrypted, and thus
%%   was an ideal point for a third party (e.g. the government) to
%%   intercept and monitor user data. Both cases demonstrate a concerted
%%   government effort to access and monitor user data atop popular cloud
%%   services.
%% \item[Lavabit:] Lavabit was a private email service with 400,000 users
%%   premised on the idea that popular free email services such as Gmail
%%   lacked adequate security and privacy guarantees (in part due to the
%%   lesser legal protections such communications receive under the U.S.
%%   third party doctrine~\cite{thompson-thirdparty}). In August 2013
%%   Lavabit shuttered its service in response to a U.S. government
%%   subpoena requiring Lavabit to turn over all of its encrypted user
%%   traffic as well as the associated SSL encryption keys necessary to
%%   decrypt it~\cite{lavabit, levsion-lavabit}. After a legal fight,
%%   Lavabit founder Ladar Levison was forced to disclose the encryption
%%   keys protecting his service. The Lavabit example shows the
%%   government's willingness to compel service operators to aid in the
%%   monitoring and collection of user data.
%% \item[Apple v. FBI:] In response to the 2015 San Bernardino shootings,
%%   the FBI attempted to compel Apple to help it decrypt one of the
%%   shooters' iPhone~\cite{ars-cookvfbi}. The form of encryption Apple
%%   uses to protect the iPhone involves a hardware-linked encryption key
%%   that can not be easily extracted from the phone, limiting
%%   out-of-band cracking opportunities. Furthermore, this key can not be
%%   used on the phone without a user-provided passcode. By default,
%%   Apple limits the number of guesses a user may make at this passcode
%%   and throttles the speed at which a user may guess passcodes. The FBI
%%   wished to compel Apple to update the software on the iPhone so that
%%   they could try to guess an unlimited number of passcodes at a high
%%   rate of speed~\cite{eff-applecrypto}.\footnote{Due to Apple's use of
%%     signature-verified code, it is not possible for the FBI (or anyone
%%     else) to update the Apple's software themselves. Instead, Apple
%%     (or the holder of Apple's cryptographic code signing key)must
%%     approve and sign any updated code before the iPhone will run
%%     it.}Apple was disinclined to acquiesce to this
%%   request~\cite{apple-fbiletter}. The case wound up being dropped by
%%   the FBI after they were able to leverage an undisclosed security
%%   vulnerability to bypass Apple's passcode guessing limits
%%   directly~\cite{ars-fbi-greyhats, ars-fbi-breakthrough}. As in the
%%   Lavabit case, this case demonstrates the government's interest in
%%   compelling companies to assist them in accessing private user data,
%%   even going so far as to potentially require companies to avoid the
%%   use of certain forms of encryption or security-enhancing features
%%   that would make such assistance difficult or impossible to provide.
%% \end{packed_desc}

\subsubsection{Unintentional Violations}

%% \begin{packed_desc}
%% \item[Apple iCloud Celebrity Photo Leak:] In 2014, a number of
%%   celebrity users of Apple's iCloud data storage
%%   service~\cite{apple-icloud} were subject to a public release of
%%   personal photos they had stored with the service. This leak was the
%%   result of a targeted attack on the corresponding users' passwords
%%   and iCloud accounts~\cite{apple-icloudleak}. These attacks appear to
%%   have been propagated over several months prior to the public
%%   release. While this leak was not a result of an overt flaw in
%%   Apple's iCloud system, the weak default security requirements for
%%   iCloud accounts made it relatively simple for attackers to
%%   compromise such accounts and steal data.
%% \item[Office of Personnel Management Breach:] In 2015, the U.S. Office
%%   of Personnel Management (OPM) announced that their systems had been
%%   breached, exposing the personal data of essentially anyone who had
%%   held or currently holds a U.S. Government security
%%   clearance~\cite{ars-opmhack, opm-cybersecurityincidents}. This
%%   breach, in addition to having high strategic value to foreign
%%   attackers, reveled sensitive personnel data of a huge number of U.S.
%%   government employees and contractors. This leak was largely due to
%%   the use of old and outdated storage and security systems employed by
%%   the OPM.
%% \item[Anthem and Premera Blue Cross Breaches:] In early 2015 two major
%%   U.S. health insurance companies were subject to attacks that breached
%%   their user records, allowing the release of personal, financial, and
%%   medical information on millions of users~\cite{krebs-anthem,
%%     krebs-premera}. While the details of the breaches were not made
%%   public, such attacks demonstrate the risk of trusting a third party
%%   with the storage of large quantities of sensitive data.
%% \item[Heartbleed, Shellshock, etc:] In addition to targeted attacks,
%%   third parties are also susceptible to software flaws. Prominent
%%   examples of such flaws include Heartbleed~\cite{heartbleed}, a flaw
%%   in OpenSSL~\cite{openssl} that allowed attackers to steal private
%%   data from many secure servers, and
%%   Shellshock~\cite{symantec-shellshock}, a GNU bash~\cite{gnu-bash}
%%   flaw that allowed user to execute arbitrary code on many web
%%   servers. Both flaws were widespread and effected large swaths of
%%   web-connected sites and services, potentially exposing many users to
%%   attacks and data breaches.
%% \end{packed_desc}

\subsubsection{Collusion Violations}


\subsection{Risk Analysis}

%%  LocalWords:  OneDrive FISC Tresorit SpiderOak MACs MitM CALEA OTR
%%  LocalWords:  TextSecure WhatsApp LastPass LastPass's KeePass Uber
