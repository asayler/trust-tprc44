\section{Modeling Trust}
\label{sec:model}

Researchers from a variety of disciplines have proposed a range of
trust definitions and models~\cite{camp2003, flowerday2006,
  grandison2000, sabater2005}. These models range from technical
models for calculating reputations via machine-learning algorithms to
sociological models for exploring legal and societal notions of
trust. In this section, I propose a trust model for exploring the
manner in which users interact with third parties across the modern
computing landscape. In particular, this model aims to provide a basis
for describing how users trust third parties with access to their
digital data and the manners in which this trust might be violated.

Before defining a model for trust, it is useful to define some of the
relevant terms used in this model. To start, I'll define
\textit{trust} as the expectation that a given entity will behave in a
promised manner. \textit{Violations} of trust thus occur whenever said
entity deviates from this expectation. Trust is closely related to two
other properties inherent in modern computing ecosystems: security and
privacy. Like trust, these terms have wide-ranging meanings across a
variety of disciplines. For the purposes of this discussion, I'll
define \textit{security} as the notion of user control over the
behavior of a given system. A \textit{secure system} is thus a system
that behaves in the manner the user desires. Facets of this notion of
security include \textit{confidentiality}, the ability to control who
can read user data, and \textit{authenticity}, the ability to control
who can modify user data. Finally, confidentiality and authenticity
provide a definition of \textit{privacy} as the ability to control
both the access and modification of user data as well as the ability
to control the meta-record of such access or modification.

When users leverage modern computing devices and services, they must
trust third party manufacturers and service providers to be good
stewards of digital data ranging from stored files to location
information to communication messages. The nature of this trust has
two main factors:

\begin{packed_desc}
\item[Degree:] How much trust must a user place in a third party
  (e.g., what capabilities do they allow a third party to exercise
  with respect to user data)?
\item[Violation:] In what manners can the third party violate this
  trust (e.g., how can the third party abuse the capabilities they
  have been granted or why might they be inclined to do so)?
\end{packed_desc}

The security and privacy of a user's data is generally dependent on
these two axes: the higher the degree of trust a user places in a
third party, the more power that party has to subvert the privacy or
security of a user's data. Similarly, the higher the risk of third
party trust violations, the higher the risk of adverse effects to
security or privacy.  Intuitively, the best ways to enhance the
security and privacy of user data is thus to minimize degree of third
party trust, to minimize the likelihood of third party trust
violations, or to minimize both.

\subsection{Degree of Trust}

Degrees of trust measure the capabilities a third party can exert over
user data. I propose that third parties can be trusted with the
following data-related capabilities:

\begin{packed_desc}
\item[Storage (S-Capability):] \hfill \\ Can a third party faithfully
  store user data and make it available to the user upon request?
  Misuse of this capability may result in a loss of user data, but
  won't necessarily result in the exposure of user data.
\item[Access (R-Capability):] \hfill \\ Can a third party read and
  interpret the user data they store? Misuse of this capability may
  result in the unapproved exposure of user data.
\item[Manipulation (W-Capability):] \hfill \\ Can a third party modify
  the private user data to which they have access? Misuse of this
  capability may result in the ability to manipulate a user
  (e.g., changing appointments on a user's calendar, etc).
\item[Meta-analysis (M-Capability):] \hfill \\ Can a third party
  gather metadata related to any user data or a user's behavior
  interacting with this data? Misuse of this capability may result in
  the ability to infer information about a user (e.g., a user's
  friends).
\end{packed_desc}

While there are likely additional capabilities users can entrust to
third parties, this collection represents the core set of data-related
capabilities most commonly entrusted to cloud service providers.

\subsection{Trust Violations}

Trust violation occurs when a third party exercises any of the above
capabilities without explicit user knowledge and consent. Put another
way, a trust violation occurs whenever a third party leverages a
capability with which they are entrusted in a manner in which the user
does not expect the capability to be leveraged. I propose classifying
such violations into four high-level categories. Each category is
defined by the manner in which the violation occurs and the
motivations behind it:

\begin{packed_desc}
\item[Implicit (P-Violation):] \hfill \\ This class of trust violation
  occurs when a third party violates a user's trust in a manner
  approved by the third party. An example might be sharing user data
  with a business partner (e.g. an advertiser). Often these violations
  aren't really ``violations'' since a user may have clicked through a
  Terms of Service agreement that ``granted'' permission for such use,
  but if the third party is willfully engaging in behavior that the
  user would not generally expect, an implicit trust violation has
  occurred.
\item[Compelled (C-Violation):] \hfill \\ This class of trust
  violation occurs when a third party is compelled by another actor to
  violate a user's trust. The most common example would be a third
  party being forced to turn over user data or records in response to
  a request from the government with jurisdiction over the party.
\item[Unintentional (U-Violation):] \hfill \\ This form of violation
  occurs when a third party unintentionally discloses or manipulates
  user data. An example would be a coding error that allows unfettered
  access to user data. Traditional ``hacking'' attacks also fall into
  this class insofar that such attacks are often possible due to
  unintentional flaws in the design of a ``secure'' system.
\item[Colluding (L-Violation):] \hfill \\ This class of violation
  occurs when multiple third parties collude to gain capabilities over
  user data beyond what the user intended each to have
  individually. An example of such a violation might occur if a user
  has granted two separate parties access to different portions of
  user data (e.g., location data stored with their cellular service
  provider and credit card transaction data stored with their bank)
  that could be combined to reveal more about the user than the user
  intended either party to know.
\end{packed_desc}

While this list of violation categories is far from exhaustive, it
does provide a good high-level framework for exploring the patterns
underlying trust violations and potential methods of mitigation.
